1. post man 설치

2. 기본 데이터 입력
http://localhost:9200/news/article/1
PUT METHOD
{
	"title" : "부산 뇌전증 환자 교통사고 대응조치…장애등급 판정자도 포함",
	"author" : "정대기 기자",
	"date" : "2016-08-02 13:50:00",
	"content": "최근 부산에서 뇌전증 환자가 차를 몰다 도심에서 17명의 사상자를 낸 사고와 관련, 경찰이 운전면허 수시적성검사 대상인 뇌전증 환자의 범위를 확대하는 내용으로 관련 법령을 손보기로 했다."
}
데이터 확인
http://localhost:9200/news/article/1

아이디를 안 넣는 경우 (PUT X POST O)
http://localhost:9200/news/article/

3.데이터 수정
POST,PUT으로 다시 입력하면 수정된다. version이 변경됨

POST 메소드로 수정한다.
{
	"doc" : {
	author : "한개 필드만 수정"
	}
}

4. 데이터 삭제
-XDELTE http://localhost:9200/news/article/1

모든 인덱스 삭제
$ curl -XDELETE 'http://localhost:9200/*'
$ curl -XDELETE 'http://localhost:9200/_all'
상용 서비스에서 호출하면 큰일

모든것을 삭제하기를 방지하기 위한 옵션
action.destructive_requires_name: true

5. 벌크 인서트
http://localhost:9200/news/article/_bulk  POST

{ "index" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
{ "title" : "부산 뇌전증 환자 교통사고 대응조치…장애등급 판정자도 포함","author" : "정대기 기자","date" : "2016-08-02 13:50:00","content": "최근 부산에서 뇌전증 환자가 차를 몰다 도심에서 17명의 사상자를 낸 사고와 관련, 경찰이 운전면허 수시적성검사 대상인 뇌전증 환자의 범위를 확대하는 내용으로 관련 법령을 손보기로 했다." }
{ "delete" : { "_index" : "test", "_type" : "type1", "_id" : "2" } }
{ "create" : { "_index" : "test", "_type" : "type1", "_id" : "3" } }
{ "field1" : "value3" }
{ "update" : {"_id" : "1", "_type" : "type1", "_index" : "test"} }
{ "doc" : {"field2" : "value2"} }

6. 벌크 DELETE
{ "delete":{ "_index" : "news", "_type" : "article", "_id" : "7" } }
{ "delete":{ "_index" : "news", "_type" : "article", "_id" : "8" } }
{ "delete":{ "_index" : "news", "_type" : "article", "_id" : "9" } }
{ "delete":{ "_index" : "news", "_type" : "article", "_id" : "10" } }

로컬 파일을 넣는법
curl -XPOST 'http://localhost:9200/_bulk' -d @1.json


7. Logstash를 이용한 색인
-logstash 다운로드
wget "https://artifacts.elastic.co/downloads/logstash/logstash-5.1.1.tar.gz"
tar zxvf logstash-5.1.1.tar.gz
cd logstash-5.1.1

-logstash elasticsearch out 플러그인 설치
bin\logstash-plugin install logstash-output-elasticsearch

-jdbc 플러그인 설치
bin\logstash-plugin install logstash-input-jdbc

jdbc 다운로드
wget "http://www.queryjet.com/static/demo/mysql-connector-java-5.1.18.jar"

-logstash 실행
./bin/logstash -f logstash.conf

input {
  jdbc {
    jdbc_driver_library => "mysql-connector-java-5.1.18.jar"
    jdbc_driver_class => "com.mysql.jdbc.Driver"
    jdbc_connection_string => "jdbc:mysql://svn.queryjet.net:23306/newsdb"
    jdbc_user => "news_user"
    jdbc_password => "news_user11"
    statement => "SELECT * FROM  NewsData LIMIT 1000"
    jdbc_paging_enabled => "true"
    jdbc_page_size => "5000"
    schedule => "* * * * *"
  }
}


filter {
  mutate {
       remove_field => [  "@version", "@timestamp"]
    }
}


output {
  stdout {
        codec => rubydebug
    }
  elasticsearch {
    hosts => ["127.0.0.1:9200"]
          index => "news"
  }
}



